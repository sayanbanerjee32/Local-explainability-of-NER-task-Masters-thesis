{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Updates from last version  \n",
    "\n",
    "* 27/07 - Initial version  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import required libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: PYTHONHASHSEED=0\n"
     ]
    }
   ],
   "source": [
    "%env PYTHONHASHSEED=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import collections\n",
    "\n",
    "import numpy as np\n",
    "import pickle\n",
    "import re\n",
    "import string\n",
    "#from sklearn.preprocessing import OneHotEncoder\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## All configurations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "w2v_model_path = '../models/glove.840B.300d/'\n",
    "moldel_outout_path = '../models_improved2/'\n",
    "training_iob_tagged_file = '../data/CoNLL-2003/eng.train'\n",
    "validation_iob_tagged_file = '../data/CoNLL-2003/eng.testa'\n",
    "test_iob_tagged_file = '../data/CoNLL-2003/eng.testb'\n",
    "save_best_weights = '../models_improved2/ner/bi_lstm_crf_improved_weights.h5'\n",
    "save_end_weights = '../models_improved2/ner/bi_lstm_crf_improved_last_epoch_weights.h5'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Word embeddings: 2196016\n"
     ]
    }
   ],
   "source": [
    "# Load GloVe's embeddings\n",
    "embeddings_index = {}\n",
    "with open(w2v_model_path + '/glove.840B.300d.txt', encoding='utf-8') as f:\n",
    "    for line in f:\n",
    "        values = line.split(' ')\n",
    "        word = values[0]\n",
    "        embedding = np.asarray(values[1:], dtype='float32')\n",
    "        embeddings_index[word] = embedding\n",
    "\n",
    "print('Word embeddings:', len(embeddings_index))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read input files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word</th>\n",
       "      <th>pos</th>\n",
       "      <th>chunk</th>\n",
       "      <th>tag</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>-DOCSTART-</td>\n",
       "      <td>-X-</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>EU</td>\n",
       "      <td>NNP</td>\n",
       "      <td>I-NP</td>\n",
       "      <td>I-ORG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>rejects</td>\n",
       "      <td>VBZ</td>\n",
       "      <td>I-VP</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>German</td>\n",
       "      <td>JJ</td>\n",
       "      <td>I-NP</td>\n",
       "      <td>I-MISC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>call</td>\n",
       "      <td>NN</td>\n",
       "      <td>I-NP</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>to</td>\n",
       "      <td>TO</td>\n",
       "      <td>I-VP</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>boycott</td>\n",
       "      <td>VB</td>\n",
       "      <td>I-VP</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>British</td>\n",
       "      <td>JJ</td>\n",
       "      <td>I-NP</td>\n",
       "      <td>I-MISC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>lamb</td>\n",
       "      <td>NN</td>\n",
       "      <td>I-NP</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         word  pos chunk     tag\n",
       "0  -DOCSTART-  -X-     O       O\n",
       "1         NaN  NaN   NaN     NaN\n",
       "2          EU  NNP  I-NP   I-ORG\n",
       "3     rejects  VBZ  I-VP       O\n",
       "4      German   JJ  I-NP  I-MISC\n",
       "5        call   NN  I-NP       O\n",
       "6          to   TO  I-VP       O\n",
       "7     boycott   VB  I-VP       O\n",
       "8     British   JJ  I-NP  I-MISC\n",
       "9        lamb   NN  I-NP       O"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# delemeter is set to blank and keep blank files\n",
    "train_iob_tagged_df = pd.read_csv(training_iob_tagged_file,delimiter=' ',skip_blank_lines=False, \n",
    "                                  header = None, names = ['word','pos','chunk','tag'])\n",
    "train_iob_tagged_df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "word     14990\n",
       "pos      14987\n",
       "chunk    14987\n",
       "tag      17165\n",
       "dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_iob_tagged_df.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data pre_processing function\n",
    "def pre_process_data_ner(iob_tagged_df):\n",
    "    # get the ids for blank rows\n",
    "    sent_idx = iob_tagged_df.index[iob_tagged_df.isnull().all(axis=1)].tolist()\n",
    "    #sent_idx[0:5]\n",
    "\n",
    "    # create sentence number list\n",
    "    sentence_num_list = [-1] # only for first row\n",
    "    e_last = 0\n",
    "    i_last = 0\n",
    "    for i, (s, e) in enumerate(zip(sent_idx[:-1],sent_idx[1:])):\n",
    "        sentence_num_list.extend([i for _ in range(s,e)])\n",
    "        e_last = e\n",
    "        i_last = i\n",
    "\n",
    "    # last few rows after last empty row\n",
    "    sentence_num_list.extend([(i_last + 1) for _ in range(e_last, iob_tagged_df.shape[0])])\n",
    "    #len(sentence_num_list),iob_tagged_df.shape\n",
    "\n",
    "    # add sentence number to data frame\n",
    "    iob_tagged_df['sentence_num'] = sentence_num_list\n",
    "    #iob_tagged_df.head()\n",
    "\n",
    "    # get the ids for -DOCSTART- rows\n",
    "    doc_idx = iob_tagged_df.index[iob_tagged_df['word']=='-DOCSTART-'].tolist()\n",
    "    doc_idx[0:5]\n",
    "\n",
    "    # create document number list\n",
    "    doc_num_list = [] \n",
    "    for i, (s, e) in enumerate(zip(doc_idx[:-1],doc_idx[1:])):\n",
    "        doc_num_list.extend([i for _ in range(s,e)])\n",
    "\n",
    "    # last few rows after last empty row\n",
    "    doc_num_list.extend([(i + 1) for _ in range(e, iob_tagged_df.shape[0])])\n",
    "    #len(doc_num_list),iob_tagged_df.shape\n",
    "\n",
    "    # add document number to data frame\n",
    "    iob_tagged_df['doc_num'] = doc_num_list\n",
    "    #iob_tagged_df.tail()\n",
    "\n",
    "    # delete all blank and doc start rows\n",
    "    delete_rows = sent_idx + doc_idx\n",
    "    print(len(sent_idx), len(doc_idx))\n",
    "    iob_tagged_df_cleaned = iob_tagged_df.drop(iob_tagged_df.index[delete_rows])\n",
    "    iob_tagged_df_cleaned.tail()\n",
    "\n",
    "    print(iob_tagged_df_cleaned.isna().sum())\n",
    "    print(iob_tagged_df_cleaned.info())\n",
    "\n",
    "    # remove rows with null values in any of the word column\n",
    "    iob_tagged_df_cleaned['word'] = iob_tagged_df_cleaned['word'].replace(' ', np.nan)\n",
    "    iob_tagged_df_cleaned = iob_tagged_df_cleaned.dropna(axis=0, subset=['word'])\n",
    "    \n",
    "    return iob_tagged_df_cleaned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14987 946\n",
      "word               3\n",
      "pos                0\n",
      "chunk              0\n",
      "tag             2178\n",
      "sentence_num       0\n",
      "doc_num            0\n",
      "dtype: int64\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 203621 entries, 2 to 219552\n",
      "Data columns (total 6 columns):\n",
      "word            203618 non-null object\n",
      "pos             203621 non-null object\n",
      "chunk           203621 non-null object\n",
      "tag             201443 non-null object\n",
      "sentence_num    203621 non-null int64\n",
      "doc_num         203621 non-null int64\n",
      "dtypes: int64(2), object(4)\n",
      "memory usage: 10.9+ MB\n",
      "None\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "word            0\n",
       "pos             0\n",
       "chunk           0\n",
       "tag             0\n",
       "sentence_num    0\n",
       "doc_num         0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_iob_tagged_df_cleaned = pre_process_data_ner(train_iob_tagged_df)\n",
    "train_iob_tagged_df_cleaned.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 201440 entries, 2 to 219552\n",
      "Data columns (total 6 columns):\n",
      "word            201440 non-null object\n",
      "pos             201440 non-null object\n",
      "chunk           201440 non-null object\n",
      "tag             201440 non-null object\n",
      "sentence_num    201440 non-null int64\n",
      "doc_num         201440 non-null int64\n",
      "dtypes: int64(2), object(4)\n",
      "memory usage: 10.8+ MB\n"
     ]
    }
   ],
   "source": [
    "train_iob_tagged_df_cleaned.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({'I-ORG': 10001,\n",
       "         'O': 167397,\n",
       "         'I-MISC': 4556,\n",
       "         'I-PER': 11128,\n",
       "         'I-LOC': 8286,\n",
       "         'B-LOC': 11,\n",
       "         'B-MISC': 37,\n",
       "         'B-ORG': 24})"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_tag_counts = collections.Counter(train_iob_tagged_df_cleaned[\"tag\"])\n",
    "train_tag_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(946, 14039, 201440)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_iob_tagged_df_cleaned.doc_num.unique()), \\\n",
    "len(train_iob_tagged_df_cleaned.sentence_num.unique()), \\\n",
    "train_iob_tagged_df_cleaned.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## IOB to IOB2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to convert IOB1 to IOB2 format for NER and chunk tags\n",
    "def iob_to_iob2(iob_tagged_df, convert_tag = 'tag', sentence_id = 'sentence_num'):\n",
    "    prev_sentence = -1\n",
    "    iob2_tag = []\n",
    "    for _, row in iob_tagged_df.iterrows():\n",
    "        cur_sentence = row[sentence_id]\n",
    "        if cur_sentence != prev_sentence:\n",
    "            prev_tag_ent = 'O'\n",
    "            prev_chunk ='O'\n",
    "\n",
    "        cur_tag = row[convert_tag]\n",
    "        if cur_tag == 'O':\n",
    "            iob2_tag.append('O')\n",
    "            cur_tag_ent = 'O'\n",
    "        else:\n",
    "            cur_tag_ent = cur_tag.split('-')[1]\n",
    "            if prev_tag_ent != cur_tag_ent:\n",
    "                iob2_tag.append('B-'+ cur_tag_ent)\n",
    "            else:\n",
    "                iob2_tag.append(cur_tag)\n",
    "\n",
    "        prev_tag_ent = cur_tag_ent\n",
    "        prev_sentence = cur_sentence\n",
    "    return iob2_tag\n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word</th>\n",
       "      <th>pos</th>\n",
       "      <th>chunk</th>\n",
       "      <th>tag</th>\n",
       "      <th>sentence_num</th>\n",
       "      <th>doc_num</th>\n",
       "      <th>iob2_tag</th>\n",
       "      <th>iob2_chunk</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>EU</td>\n",
       "      <td>NNP</td>\n",
       "      <td>I-NP</td>\n",
       "      <td>I-ORG</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>B-ORG</td>\n",
       "      <td>B-NP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>rejects</td>\n",
       "      <td>VBZ</td>\n",
       "      <td>I-VP</td>\n",
       "      <td>O</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>O</td>\n",
       "      <td>B-VP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>German</td>\n",
       "      <td>JJ</td>\n",
       "      <td>I-NP</td>\n",
       "      <td>I-MISC</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>B-MISC</td>\n",
       "      <td>B-NP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>call</td>\n",
       "      <td>NN</td>\n",
       "      <td>I-NP</td>\n",
       "      <td>O</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>O</td>\n",
       "      <td>I-NP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>to</td>\n",
       "      <td>TO</td>\n",
       "      <td>I-VP</td>\n",
       "      <td>O</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>O</td>\n",
       "      <td>B-VP</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      word  pos chunk     tag  sentence_num  doc_num iob2_tag iob2_chunk\n",
       "2       EU  NNP  I-NP   I-ORG             0        0    B-ORG       B-NP\n",
       "3  rejects  VBZ  I-VP       O             0        0        O       B-VP\n",
       "4   German   JJ  I-NP  I-MISC             0        0   B-MISC       B-NP\n",
       "5     call   NN  I-NP       O             0        0        O       I-NP\n",
       "6       to   TO  I-VP       O             0        0        O       B-VP"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_iob_tagged_df_cleaned[\"iob2_tag\"] = iob_to_iob2(train_iob_tagged_df_cleaned)\n",
    "train_iob_tagged_df_cleaned[\"iob2_chunk\"] = iob_to_iob2(train_iob_tagged_df_cleaned,'chunk')\n",
    "train_iob_tagged_df_cleaned.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_iob_tagged_df_cleaned.drop(['chunk','tag'], axis = 1, inplace = True)\n",
    "train_iob_tagged_df_cleaned.rename(columns = {'iob2_tag':'tag',\n",
    "                                              'iob2_chunk':'chunk'}, inplace = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reduce sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 201440 entries, 2 to 219552\n",
      "Data columns (total 6 columns):\n",
      "word            201440 non-null object\n",
      "pos             201440 non-null object\n",
      "sentence_num    201440 non-null int64\n",
      "doc_num         201440 non-null int64\n",
      "tag             201440 non-null object\n",
      "chunk           201440 non-null object\n",
      "dtypes: int64(2), object(4)\n",
      "memory usage: 10.8+ MB\n"
     ]
    }
   ],
   "source": [
    "train_iob_tagged_df_cleaned.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    14039.000000\n",
       "mean        14.348600\n",
       "std         11.448242\n",
       "min          1.000000\n",
       "25%          6.000000\n",
       "50%         10.000000\n",
       "75%         22.000000\n",
       "max        113.000000\n",
       "Name: 0, dtype: float64"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# statistics on words in sentences\n",
    "sent_word_stat = train_iob_tagged_df_cleaned.groupby('sentence_num').size().reset_index()\n",
    "sent_word_stat.loc[:,0].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reduce_sentence_length_by_word(df, max_word, sentence_id_col_name):\n",
    "    sent_word_stat = df.groupby(sentence_id_col_name).size().reset_index()\n",
    "    # keep sentences that less than or equal to (appproximately) 3rd quartile of number of words\n",
    "    thirdq_list_sentence_id = list(sent_word_stat.loc[sent_word_stat[0] <= max_word,sentence_id_col_name])\n",
    "    df_reduced = df.loc[df.sentence_num.isin(thirdq_list_sentence_id),:]\n",
    "    return df_reduced"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # keep sentences that less than or equal to (appproximately) 3rd quartile of number of words\n",
    "# thirdq_list_sentence_id = list(sent_word_stat.loc[sent_word_stat[0] <= 25,'sentence_num'])\n",
    "# len(thirdq_list_sentence_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_iob_tagged_df_cleaned_reduced = train_iob_tagged_df_cleaned.loc[train_iob_tagged_df_cleaned.sentence_num.\\\n",
    "#                                                                   isin(thirdq_list_sentence_id),:]\n",
    "# train_iob_tagged_df_cleaned_reduced.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(108975, 6)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_words = 25\n",
    "train_iob_tagged_df_cleaned_reduced = reduce_sentence_length_by_word(train_iob_tagged_df_cleaned,\n",
    "                                                                     max_words,'sentence_num')\n",
    "train_iob_tagged_df_cleaned_reduced.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's reduce the number pf sentences based on tag density"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sent_tag_stat_raw = train_iob_tagged_df_cleaned_reduced.copy()\n",
    "# sent_tag_stat_raw['tag_type'] = sent_tag_stat_raw['tag'].apply(lambda x: x[:2] if x != 'O' else 'O')\n",
    "# sent_tag_stat_raw.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # keep onlly the words having B- tags\n",
    "# sent_tag_stat_raw = sent_tag_stat_raw.loc[sent_tag_stat_raw.tag_type == 'B-',:]\n",
    "# # statistics on tags in sentences\n",
    "# sent_tag_stat = sent_tag_stat_raw.groupby('sentence_num').size().reset_index()\n",
    "# sent_tag_stat.loc[:,0].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # arrange sentences by number of tags\n",
    "# sent_tag_stat = sent_tag_stat.sort_values([0],ascending = False).reset_index()\n",
    "# sent_tag_stat.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # keep 90% of the sentences based on number of tags\n",
    "# selected_sentences_by_tagno = sent_tag_stat.iloc[range(round(len(sent_tag_stat)*0.9)),:]['sentence_num']\n",
    "# len(selected_sentences_by_tagno)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train_iob_tagged_df_cleaned_reduced = train_iob_tagged_df_cleaned_reduced.loc[train_iob_tagged_df_cleaned_reduced.sentence_num.\\\n",
    "#                                                                   isin(selected_sentences_by_tagno),:]\n",
    "# train_iob_tagged_df_cleaned_reduced.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({'B-ORG': 4484,\n",
       "         'O': 87243,\n",
       "         'B-MISC': 1716,\n",
       "         'B-PER': 4283,\n",
       "         'I-PER': 2998,\n",
       "         'B-LOC': 4789,\n",
       "         'I-ORG': 2168,\n",
       "         'I-LOC': 590,\n",
       "         'I-MISC': 704})"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_tag_counts = collections.Counter(train_iob_tagged_df_cleaned_reduced[\"tag\"])\n",
    "train_tag_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['I-MISC', 'B-PER', 'B-MISC', 'I-ORG', 'B-LOC', 'I-LOC', 'O', 'B-ORG', 'I-PER']"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tags = list(set(train_iob_tagged_df_cleaned_reduced['tag'].values))\n",
    "n_tags = len(tags)\n",
    "tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(946, 11289, 108975)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_iob_tagged_df_cleaned_reduced.doc_num.unique()), \\\n",
    "len(train_iob_tagged_df_cleaned_reduced.sentence_num.unique()), \\\n",
    "train_iob_tagged_df_cleaned_reduced.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Limit Vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reduction of Vocab wil be based on original data set, nt reduced\n",
    "word_counts = collections.Counter(train_iob_tagged_df_cleaned[\"word\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Limit the vocab that we will use to words that appear ≥ threshold or are in GloVe\n",
    "\n",
    "# Define threshold\n",
    "threshold = 10\n",
    "\n",
    "#dictionary to convert words to integers\n",
    "vocab_to_int = {} \n",
    "\n",
    "value = 0\n",
    "for word, count in word_counts.items():\n",
    "    if count >= threshold or word in embeddings_index:\n",
    "        vocab_to_int[word] = value\n",
    "        value += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Number of Unique Words: 23621\n",
      "Number of Words we will use: 21399\n",
      "Percent of Words we will use: 90.59%\n"
     ]
    }
   ],
   "source": [
    "# Special tokens that will be added to our vocab\n",
    "codes = [\"<UNK>\",\"<PAD>\"]   \n",
    "\n",
    "# Add codes to vocab\n",
    "for code in codes:\n",
    "    vocab_to_int[code] = len(vocab_to_int)\n",
    "\n",
    "# Dictionary to convert integers to words\n",
    "int_to_vocab = {}\n",
    "for word, value in vocab_to_int.items():\n",
    "    int_to_vocab[value] = word\n",
    "\n",
    "usage_ratio = round(len(vocab_to_int) / len(word_counts),4)*100\n",
    "\n",
    "print(\"Total Number of Unique Words:\", len(word_counts))\n",
    "print(\"Number of Words we will use:\", len(vocab_to_int))\n",
    "print(\"Percent of Words we will use: {}%\".format(usage_ratio))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(moldel_outout_path + '/ner_bilstm_crf_improved_train_vocab2int.pkl','wb') as _f:\n",
    "    pickle.dump(vocab_to_int,_f,protocol = pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21399 16\n"
     ]
    }
   ],
   "source": [
    "# Need to use 300 for embedding dimensions to match GloVe's vectors.\n",
    "embedding_dim = 300\n",
    "\n",
    "random_embd_count = 0\n",
    "nb_words = len(vocab_to_int)\n",
    "# Create matrix with default values of zero\n",
    "word_embedding_matrix = np.zeros((nb_words, embedding_dim))\n",
    "for word, i in vocab_to_int.items():\n",
    "    if word in embeddings_index:\n",
    "        word_embedding_matrix[i] = embeddings_index[word]\n",
    "    else:\n",
    "        # If word not in GloVe, create a random embedding for it\n",
    "        new_embedding = np.array(np.random.uniform(-1.0, 1.0, embedding_dim))\n",
    "        embeddings_index[word] = new_embedding\n",
    "        word_embedding_matrix[i] = new_embedding\n",
    "        random_embd_count += 1\n",
    "\n",
    "# Check if value matches len(vocab_to_int)\n",
    "print(len(word_embedding_matrix), random_embd_count)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare for NER training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.utils import to_categorical\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "# from sklearn.impute import SimpleImputer\n",
    "# from sklearn.compose import ColumnTransformer\n",
    "# from sklearn.pipeline import make_pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SentenceGetter(object):\n",
    "    \n",
    "    def __init__(self, data):\n",
    "        self.n_sent = 1\n",
    "        self.data = data\n",
    "        self.empty = False\n",
    "        agg_func = lambda s: [(w, p, c, t) for w, p, c, t in zip(s[\"word\"].values.tolist(),\n",
    "                                                           s[\"pos\"].values.tolist(),\n",
    "                                                            s[\"chunk\"].values.tolist(),\n",
    "                                                           s[\"tag\"].values.tolist())]\n",
    "        self.grouped = self.data.groupby(\"sentence_num\").apply(agg_func)\n",
    "        self.sentences = [s for s in self.grouped]\n",
    "    \n",
    "    def get_next(self):\n",
    "        try:\n",
    "            s = self.grouped[\"Sentence: {}\".format(self.n_sent)]\n",
    "            self.n_sent += 1\n",
    "            return s\n",
    "        except:\n",
    "            return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# using sentences from reduced data set\n",
    "train_getter = SentenceGetter(train_iob_tagged_df_cleaned_reduced)\n",
    "train_sentences = train_getter.sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'EU rejects German call to boycott British lamb .'"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels = [[s[3] for s in sent] for sent in train_sentences]\n",
    "sentences = [\" \".join([str(s[0]) for s in sent]) for sent in train_sentences]\n",
    "sentences[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "48"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(sentences[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['B-ORG', 'O', 'B-MISC', 'O', 'O', 'O', 'B-MISC', 'O', 'O']\n"
     ]
    }
   ],
   "source": [
    "print(labels[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find the length of sentences\n",
    "lengths = [len(sent.split()) for sent in sentences]\n",
    "\n",
    "# Create a dataframe so that the values can be inspected\n",
    "lengths = pd.DataFrame(lengths, columns=['counts'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    11289.000000\n",
       "mean         9.653202\n",
       "std          6.370189\n",
       "min          1.000000\n",
       "25%          5.000000\n",
       "50%          8.000000\n",
       "75%         13.000000\n",
       "max         25.000000\n",
       "Name: counts, dtype: float64"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lengths.counts.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'I-MISC': 0,\n",
       " 'B-PER': 1,\n",
       " 'B-MISC': 2,\n",
       " 'I-ORG': 3,\n",
       " 'B-LOC': 4,\n",
       " 'I-LOC': 5,\n",
       " 'O': 6,\n",
       " 'B-ORG': 7,\n",
       " 'I-PER': 8}"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_len = 25\n",
    "tag2idx = {t: i for i, t in enumerate(tags)}\n",
    "tag2idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['I-MISC', 'B-PER', 'B-MISC', 'I-ORG', 'B-LOC', 'I-LOC', 'O', 'B-ORG', 'I-PER']"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(moldel_outout_path + '/ner_bilstm_crf_improved_tag2idx.pkl','wb') as _f:\n",
    "    pickle.dump(tag2idx,_f,protocol = pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: 'I-MISC',\n",
       " 1: 'B-PER',\n",
       " 2: 'B-MISC',\n",
       " 3: 'I-ORG',\n",
       " 4: 'B-LOC',\n",
       " 5: 'I-LOC',\n",
       " 6: 'O',\n",
       " 7: 'B-ORG',\n",
       " 8: 'I-PER'}"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "idx2tag = {i: w for w, i in tag2idx.items()}\n",
    "idx2tag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(moldel_outout_path + '/ner_bilstm_crf_improved_idx2tag.pkl','wb') as _f:\n",
    "    pickle.dump(idx2tag,_f,protocol = pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "25"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = [[vocab_to_int[w[0]] if w[0] in vocab_to_int.keys() else vocab_to_int['<UNK>'] for w in s]\\\n",
    "                                                            for s in train_sentences]\n",
    "X = pad_sequences(maxlen = max_len, sequences = X, padding  = 'post', value = vocab_to_int['<PAD>'])\n",
    "len(X[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = [[tag2idx[w[3]] for w in s] for s in train_sentences]\n",
    "y = pad_sequences(maxlen = max_len, sequences = y, padding  = 'post', value = tag2idx['O'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = [to_categorical(i, num_classes = n_tags) for i in y]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_val, y_train, y_val, train_idx, val_idx = train_test_split(X, y, range(len(X)), test_size = 0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((10160, 25), 10160)"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape,len(y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NER Model setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import initializers\n",
    "from keras.models import Model, Input\n",
    "from keras.layers import LSTM, Embedding, Dense, TimeDistributed, SpatialDropout1D, Bidirectional, concatenate,\\\n",
    "                            BatchNormalization\n",
    "from keras.callbacks import Callback, ModelCheckpoint, EarlyStopping, ReduceLROnPlateau\n",
    "from keras_contrib.layers import CRF\n",
    "from seqeval.callbacks import F1Metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hyper parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "dropout = 0.1\n",
    "weights = initializers.TruncatedNormal(mean = 0.0, stddev = 0.1, seed = 2)\n",
    "num_batch_size = 64\n",
    "num_epochs = 20"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Metric Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras.backend as K\n",
    "def get_f1(y_true, y_pred): #taken from old keras source code\n",
    "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "    possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n",
    "    predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\n",
    "    precision = true_positives / (predicted_positives + K.epsilon())\n",
    "    recall = true_positives / (possible_positives + K.epsilon())\n",
    "    f1_val = 2*(precision*recall)/(precision+recall+K.epsilon())\n",
    "    return f1_val"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import random as python_random\n",
    "\n",
    "# The below is necessary for starting Numpy generated random numbers\n",
    "# in a well-defined initial state.\n",
    "np.random.seed(123)\n",
    "\n",
    "# The below is necessary for starting core Python generated random numbers\n",
    "# in a well-defined state.\n",
    "python_random.seed(123)\n",
    "\n",
    "# The below set_seed() will make random number generation\n",
    "# in the TensorFlow backend have a well-defined initial state.\n",
    "# For further details, see:\n",
    "# https://www.tensorflow.org/api_docs/python/tf/random/set_seed\n",
    "tf.set_random_seed(1234)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda\\envs\\XAI_NER\\lib\\site-packages\\keras_contrib-2.0.8-py3.6.egg\\keras_contrib\\layers\\crf.py:346: UserWarning: CRF.loss_function is deprecated and it might be removed in the future. Please use losses.crf_loss instead.\n",
      "D:\\Anaconda\\envs\\XAI_NER\\lib\\site-packages\\keras_contrib-2.0.8-py3.6.egg\\keras_contrib\\layers\\crf.py:353: UserWarning: CRF.accuracy is deprecated and it might be removed in the future. Please use metrics.crf_accuracy\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "main_input (InputLayer)      (None, 25)                0         \n",
      "_________________________________________________________________\n",
      "embedding_1 (Embedding)      (None, 25, 300)           6419700   \n",
      "_________________________________________________________________\n",
      "bidirectional_1 (Bidirection (None, 25, 100)           140400    \n",
      "_________________________________________________________________\n",
      "time_distributed_1 (TimeDist (None, 25, 50)            5050      \n",
      "_________________________________________________________________\n",
      "crf_1 (CRF)                  (None, 25, 9)             558       \n",
      "=================================================================\n",
      "Total params: 6,565,708\n",
      "Trainable params: 6,565,708\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "main_input = Input(shape=(max_len,),name = 'main_input')\n",
    "embed_layer = Embedding(input_dim=nb_words, output_dim=embedding_dim, input_length=max_len,\n",
    "                 mask_zero = True,\n",
    "                 weights = [word_embedding_matrix])(main_input)\n",
    "#drpout1 = SpatialDropout1D(0.1)(embed_layer)\n",
    "bi_lstm_layer = Bidirectional(LSTM(units=50, return_sequences=True,\n",
    "                                   kernel_initializer = weights,\n",
    "                                   recurrent_dropout=0.1))(embed_layer)\n",
    "dense_layer = TimeDistributed(Dense(50, activation=\"relu\"))(bi_lstm_layer)\n",
    "\n",
    "# aux_input = Input(shape = (max_len,aux_train_input.shape[2],), name = 'aux_inputs')\n",
    "# merge_out = concatenate([dense_layer,aux_input])\n",
    "# #norm_out = BatchNormalization()(merge_out)\n",
    "\n",
    "crf = CRF(n_tags, learn_mode='marginal')  # CRF layer\n",
    "final_out = crf(dense_layer)  # output\n",
    "\n",
    "model = Model(inputs = main_input, outputs = final_out)\n",
    "model.compile(optimizer=\"adam\", #\"rmsprop\",\n",
    "              loss=crf.loss_function,\n",
    "              metrics=[crf.accuracy, get_f1])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 9144 samples, validate on 1016 samples\n",
      "Epoch 1/20\n",
      "9144/9144 [==============================] - 41s 5ms/step - loss: 0.2677 - crf_marginal_accuracy: 0.9284 - get_f1: 0.9148 - val_loss: 0.1188 - val_crf_marginal_accuracy: 0.9638 - val_get_f1: 0.9641\n",
      "Epoch 2/20\n",
      "9144/9144 [==============================] - 37s 4ms/step - loss: 0.0749 - crf_marginal_accuracy: 0.9783 - get_f1: 0.9783 - val_loss: 0.0546 - val_crf_marginal_accuracy: 0.9848 - val_get_f1: 0.9855\n",
      "Epoch 3/20\n",
      "9144/9144 [==============================] - 36s 4ms/step - loss: 0.0335 - crf_marginal_accuracy: 0.9909 - get_f1: 0.9910 - val_loss: 0.0390 - val_crf_marginal_accuracy: 0.9891 - val_get_f1: 0.9897\n",
      "Epoch 4/20\n",
      "9144/9144 [==============================] - 36s 4ms/step - loss: 0.0171 - crf_marginal_accuracy: 0.9956 - get_f1: 0.9957 - val_loss: 0.0335 - val_crf_marginal_accuracy: 0.9910 - val_get_f1: 0.9915\n",
      "Epoch 5/20\n",
      "9144/9144 [==============================] - 36s 4ms/step - loss: 0.0095 - crf_marginal_accuracy: 0.9977 - get_f1: 0.9978 - val_loss: 0.0333 - val_crf_marginal_accuracy: 0.9917 - val_get_f1: 0.9919\n",
      "Epoch 6/20\n",
      "9144/9144 [==============================] - 37s 4ms/step - loss: 0.0057 - crf_marginal_accuracy: 0.9987 - get_f1: 0.9987 - val_loss: 0.0337 - val_crf_marginal_accuracy: 0.9915 - val_get_f1: 0.9917\n",
      "Epoch 7/20\n",
      "9144/9144 [==============================] - 40s 4ms/step - loss: 0.0036 - crf_marginal_accuracy: 0.9992 - get_f1: 0.9992 - val_loss: 0.0345 - val_crf_marginal_accuracy: 0.9916 - val_get_f1: 0.9918\n",
      "Epoch 8/20\n",
      "9144/9144 [==============================] - 40s 4ms/step - loss: 0.0026 - crf_marginal_accuracy: 0.9994 - get_f1: 0.9994 - val_loss: 0.0359 - val_crf_marginal_accuracy: 0.9913 - val_get_f1: 0.9915\n",
      "\n",
      "Epoch 00008: ReduceLROnPlateau reducing learning rate to 0.00020000000949949026.\n",
      "Epoch 9/20\n",
      "9144/9144 [==============================] - 42s 5ms/step - loss: 0.0018 - crf_marginal_accuracy: 0.9996 - get_f1: 0.9996 - val_loss: 0.0356 - val_crf_marginal_accuracy: 0.9914 - val_get_f1: 0.9917\n",
      "Epoch 10/20\n",
      "9144/9144 [==============================] - 43s 5ms/step - loss: 0.0015 - crf_marginal_accuracy: 0.9997 - get_f1: 0.9997 - val_loss: 0.0355 - val_crf_marginal_accuracy: 0.9914 - val_get_f1: 0.9917\n",
      "Epoch 00010: early stopping\n"
     ]
    }
   ],
   "source": [
    "callbacks = [ModelCheckpoint(save_best_weights, monitor = 'val_loss', save_best_only = True),\n",
    "            EarlyStopping(monitor = 'val_loss', patience = 5, verbose = 1, mode = 'auto'),\n",
    "            ReduceLROnPlateau(monitor = 'val_loss', factor = 0.2, verbose = 1, patience = 3)]\n",
    "            #F1Metrics(idx2tag)]\n",
    "\n",
    "history = model.fit(X_train,\n",
    "                    np.array(y_train),\n",
    "                    batch_size = num_batch_size, \n",
    "                    epochs = num_epochs,\n",
    "                    validation_split=0.1, \n",
    "                    verbose = True,\n",
    "                    shuffle = True,\n",
    "                   callbacks = callbacks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(save_end_weights)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "from seqeval.metrics import precision_score, recall_score, f1_score, classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1129/1129 [==============================] - 4s 3ms/step\n"
     ]
    }
   ],
   "source": [
    "val_pred = model.predict(X_val, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pred2label(pred):\n",
    "    out = []\n",
    "    for pred_i in pred:\n",
    "        out_i = []\n",
    "        for p in pred_i:\n",
    "            p_i = np.argmax(p)\n",
    "            out_i.append(idx2tag[p_i].replace(\"PAD\", \"O\"))\n",
    "        out.append(out_i)\n",
    "    return out\n",
    "    \n",
    "val_pred_labels = pred2label(val_pred)\n",
    "val_labels = pred2label(y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1-score: 89.8%\n",
      "           precision    recall  f1-score   support\n",
      "\n",
      "      ORG       0.85      0.88      0.87       410\n",
      "      LOC       0.95      0.94      0.94       451\n",
      "      PER       0.91      0.93      0.92       406\n",
      "     MISC       0.79      0.82      0.81       171\n",
      "\n",
      "micro avg       0.89      0.90      0.90      1438\n",
      "macro avg       0.89      0.90      0.90      1438\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"F1-score: {:.1%}\".format(f1_score(val_labels, val_pred_labels)))\n",
    "print(classification_report(val_labels, val_pred_labels))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hold out dataset - A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word</th>\n",
       "      <th>pos</th>\n",
       "      <th>chunk</th>\n",
       "      <th>tag</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>-DOCSTART-</td>\n",
       "      <td>-X-</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>CRICKET</td>\n",
       "      <td>NNP</td>\n",
       "      <td>I-NP</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>-</td>\n",
       "      <td>:</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>LEICESTERSHIRE</td>\n",
       "      <td>NNP</td>\n",
       "      <td>I-NP</td>\n",
       "      <td>I-ORG</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             word  pos chunk    tag\n",
       "0      -DOCSTART-  -X-     O      O\n",
       "1             NaN  NaN   NaN    NaN\n",
       "2         CRICKET  NNP  I-NP      O\n",
       "3               -    :     O      O\n",
       "4  LEICESTERSHIRE  NNP  I-NP  I-ORG"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "validate_iob_tag_df = pd.read_csv(validation_iob_tagged_file,delimiter=' ',skip_blank_lines=False, \n",
    "                                  header = None, names = ['word','pos','chunk','tag'])\n",
    "validate_iob_tag_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3467 216\n",
      "word              3\n",
      "pos               0\n",
      "chunk             0\n",
      "tag             640\n",
      "sentence_num      0\n",
      "doc_num           0\n",
      "dtype: int64\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 51362 entries, 2 to 55042\n",
      "Data columns (total 6 columns):\n",
      "word            51359 non-null object\n",
      "pos             51362 non-null object\n",
      "chunk           51362 non-null object\n",
      "tag             50722 non-null object\n",
      "sentence_num    51362 non-null int64\n",
      "doc_num         51362 non-null int64\n",
      "dtypes: int64(2), object(4)\n",
      "memory usage: 2.7+ MB\n",
      "None\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "word            0\n",
       "pos             0\n",
       "chunk           0\n",
       "tag             0\n",
       "sentence_num    0\n",
       "doc_num         0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "validate_iob_tagged_df_cleaned = pre_process_data_ner(validate_iob_tag_df)\n",
    "validate_iob_tagged_df_cleaned.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(216, 3250, 50719)"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(validate_iob_tagged_df_cleaned.doc_num.unique()), \\\n",
    "len(validate_iob_tagged_df_cleaned.sentence_num.unique()), \\\n",
    "validate_iob_tagged_df_cleaned.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({'O': 42120,\n",
       "         'I-ORG': 2092,\n",
       "         'I-LOC': 2094,\n",
       "         'I-MISC': 1264,\n",
       "         'I-PER': 3145,\n",
       "         'B-MISC': 4})"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "validate_tag_counts = collections.Counter(validate_iob_tagged_df_cleaned[\"tag\"])\n",
    "validate_tag_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word</th>\n",
       "      <th>pos</th>\n",
       "      <th>chunk</th>\n",
       "      <th>tag</th>\n",
       "      <th>sentence_num</th>\n",
       "      <th>doc_num</th>\n",
       "      <th>iob2_tag</th>\n",
       "      <th>iob2_chunk</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>CRICKET</td>\n",
       "      <td>NNP</td>\n",
       "      <td>I-NP</td>\n",
       "      <td>O</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>O</td>\n",
       "      <td>B-NP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>-</td>\n",
       "      <td>:</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>LEICESTERSHIRE</td>\n",
       "      <td>NNP</td>\n",
       "      <td>I-NP</td>\n",
       "      <td>I-ORG</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>B-ORG</td>\n",
       "      <td>B-NP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>TAKE</td>\n",
       "      <td>NNP</td>\n",
       "      <td>I-NP</td>\n",
       "      <td>O</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>O</td>\n",
       "      <td>I-NP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>OVER</td>\n",
       "      <td>IN</td>\n",
       "      <td>I-PP</td>\n",
       "      <td>O</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>O</td>\n",
       "      <td>B-PP</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             word  pos chunk    tag  sentence_num  doc_num iob2_tag iob2_chunk\n",
       "2         CRICKET  NNP  I-NP      O             0        0        O       B-NP\n",
       "3               -    :     O      O             0        0        O          O\n",
       "4  LEICESTERSHIRE  NNP  I-NP  I-ORG             0        0    B-ORG       B-NP\n",
       "5            TAKE  NNP  I-NP      O             0        0        O       I-NP\n",
       "6            OVER   IN  I-PP      O             0        0        O       B-PP"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "validate_iob_tagged_df_cleaned[\"iob2_tag\"] = iob_to_iob2(validate_iob_tagged_df_cleaned)\n",
    "validate_iob_tagged_df_cleaned[\"iob2_chunk\"] = iob_to_iob2(validate_iob_tagged_df_cleaned,'chunk')\n",
    "validate_iob_tagged_df_cleaned.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "validate_iob_tagged_df_cleaned.drop(['chunk','tag'], axis = 1, inplace = True)\n",
    "validate_iob_tagged_df_cleaned.rename(columns = {'iob2_tag':'tag',\n",
    "                                              'iob2_chunk':'chunk'}, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(24988, 6)"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "validate_iob_tagged_df_cleaned_reduced = reduce_sentence_length_by_word(validate_iob_tagged_df_cleaned,\n",
    "                                                                     max_words,'sentence_num')\n",
    "validate_iob_tagged_df_cleaned_reduced.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(216, 2505, 24988)"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(validate_iob_tagged_df_cleaned_reduced.doc_num.unique()), \\\n",
    "len(validate_iob_tagged_df_cleaned_reduced.sentence_num.unique()), \\\n",
    "validate_iob_tagged_df_cleaned_reduced.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({'O': 20121,\n",
       "         'B-ORG': 839,\n",
       "         'B-LOC': 1180,\n",
       "         'B-PER': 1008,\n",
       "         'I-PER': 675,\n",
       "         'B-MISC': 460,\n",
       "         'I-MISC': 193,\n",
       "         'I-LOC': 156,\n",
       "         'I-ORG': 356})"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "validate_tag_counts = collections.Counter(validate_iob_tagged_df_cleaned_reduced[\"tag\"])\n",
    "validate_tag_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "validate_getter = SentenceGetter(validate_iob_tagged_df_cleaned_reduced)\n",
    "validate_sentences = validate_getter.sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "25"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_validate = [[vocab_to_int[w[0]] if w[0] in vocab_to_int.keys() else vocab_to_int['<UNK>'] for w in s]\\\n",
    "                                                            for s in validate_sentences]\n",
    "X_validate = pad_sequences(maxlen = max_len, sequences = X_validate, padding  = 'post', value = vocab_to_int['<PAD>'])\n",
    "len(X_validate[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_validate = [[tag2idx[w[3]] for w in s] for s in validate_sentences]\n",
    "y_validate = pad_sequences(maxlen = max_len, sequences = y_validate, padding  = 'post', value = tag2idx['O'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_validate = [to_categorical(i, num_classes = n_tags) for i in y_validate]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2505/2505 [==============================] - 7s 3ms/step\n"
     ]
    }
   ],
   "source": [
    "validate_pred = model.predict(X_validate, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "validate_pred_labels = pred2label(validate_pred)\n",
    "validate_labels = pred2label(y_validate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1-score: 82.5%\n",
      "           precision    recall  f1-score   support\n",
      "\n",
      "      ORG       0.74      0.80      0.77       839\n",
      "      PER       0.80      0.84      0.82      1008\n",
      "     MISC       0.74      0.80      0.77       460\n",
      "      LOC       0.94      0.85      0.90      1180\n",
      "\n",
      "micro avg       0.82      0.83      0.83      3487\n",
      "macro avg       0.83      0.83      0.83      3487\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"F1-score: {:.1%}\".format(f1_score(validate_labels, validate_pred_labels)))\n",
    "print(classification_report(validate_labels, validate_pred_labels))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hold out dataset - B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word</th>\n",
       "      <th>pos</th>\n",
       "      <th>chunk</th>\n",
       "      <th>tag</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>-DOCSTART-</td>\n",
       "      <td>-X-</td>\n",
       "      <td>-X-</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>SOCCER</td>\n",
       "      <td>NN</td>\n",
       "      <td>I-NP</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>-</td>\n",
       "      <td>:</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>JAPAN</td>\n",
       "      <td>NNP</td>\n",
       "      <td>I-NP</td>\n",
       "      <td>I-LOC</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         word  pos chunk    tag\n",
       "0  -DOCSTART-  -X-   -X-      O\n",
       "1         NaN  NaN   NaN    NaN\n",
       "2      SOCCER   NN  I-NP      O\n",
       "3           -    :     O      O\n",
       "4       JAPAN  NNP  I-NP  I-LOC"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_iob_tag_df = pd.read_csv(test_iob_tagged_file,delimiter=' ',skip_blank_lines=False, \n",
    "                                  header = None, names = ['word','pos','chunk','tag'])\n",
    "test_iob_tag_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3685 231\n",
      "word              0\n",
      "pos               0\n",
      "chunk             0\n",
      "tag             421\n",
      "sentence_num      0\n",
      "doc_num           0\n",
      "dtype: int64\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 46435 entries, 2 to 50348\n",
      "Data columns (total 6 columns):\n",
      "word            46435 non-null object\n",
      "pos             46435 non-null object\n",
      "chunk           46435 non-null object\n",
      "tag             46014 non-null object\n",
      "sentence_num    46435 non-null int64\n",
      "doc_num         46435 non-null int64\n",
      "dtypes: int64(2), object(4)\n",
      "memory usage: 2.5+ MB\n",
      "None\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "word            0\n",
       "pos             0\n",
       "chunk           0\n",
       "tag             0\n",
       "sentence_num    0\n",
       "doc_num         0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_iob_tagged_df_cleaned = pre_process_data_ner(test_iob_tag_df)\n",
    "test_iob_tagged_df_cleaned.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(231, 3453, 46014)"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(test_iob_tagged_df_cleaned.doc_num.unique()), \\\n",
    "len(test_iob_tagged_df_cleaned.sentence_num.unique()), \\\n",
    "test_iob_tagged_df_cleaned.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({'O': 37902,\n",
       "         'I-LOC': 1919,\n",
       "         'I-PER': 2773,\n",
       "         'I-MISC': 909,\n",
       "         'I-ORG': 2491,\n",
       "         'B-ORG': 5,\n",
       "         'B-MISC': 9,\n",
       "         'B-LOC': 6})"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_tag_counts = collections.Counter(test_iob_tagged_df_cleaned[\"tag\"])\n",
    "test_tag_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word</th>\n",
       "      <th>pos</th>\n",
       "      <th>chunk</th>\n",
       "      <th>tag</th>\n",
       "      <th>sentence_num</th>\n",
       "      <th>doc_num</th>\n",
       "      <th>iob2_tag</th>\n",
       "      <th>iob2_chunk</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>SOCCER</td>\n",
       "      <td>NN</td>\n",
       "      <td>I-NP</td>\n",
       "      <td>O</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>O</td>\n",
       "      <td>B-NP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>-</td>\n",
       "      <td>:</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>JAPAN</td>\n",
       "      <td>NNP</td>\n",
       "      <td>I-NP</td>\n",
       "      <td>I-LOC</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>B-LOC</td>\n",
       "      <td>B-NP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>GET</td>\n",
       "      <td>VB</td>\n",
       "      <td>I-VP</td>\n",
       "      <td>O</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>O</td>\n",
       "      <td>B-VP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>LUCKY</td>\n",
       "      <td>NNP</td>\n",
       "      <td>I-NP</td>\n",
       "      <td>O</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>O</td>\n",
       "      <td>B-NP</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     word  pos chunk    tag  sentence_num  doc_num iob2_tag iob2_chunk\n",
       "2  SOCCER   NN  I-NP      O             0        0        O       B-NP\n",
       "3       -    :     O      O             0        0        O          O\n",
       "4   JAPAN  NNP  I-NP  I-LOC             0        0    B-LOC       B-NP\n",
       "5     GET   VB  I-VP      O             0        0        O       B-VP\n",
       "6   LUCKY  NNP  I-NP      O             0        0        O       B-NP"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_iob_tagged_df_cleaned[\"iob2_tag\"] = iob_to_iob2(test_iob_tagged_df_cleaned)\n",
    "test_iob_tagged_df_cleaned[\"iob2_chunk\"] = iob_to_iob2(test_iob_tagged_df_cleaned,'chunk')\n",
    "test_iob_tagged_df_cleaned.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_iob_tagged_df_cleaned.drop(['chunk','tag'], axis = 1, inplace = True)\n",
    "test_iob_tagged_df_cleaned.rename(columns = {'iob2_tag':'tag',\n",
    "                                              'iob2_chunk':'chunk'}, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(26456, 6)"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_iob_tagged_df_cleaned_reduced = reduce_sentence_length_by_word(test_iob_tagged_df_cleaned,\n",
    "                                                                     max_words,'sentence_num')\n",
    "test_iob_tagged_df_cleaned_reduced.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(231, 2884, 26456)"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(test_iob_tagged_df_cleaned_reduced.doc_num.unique()), \\\n",
    "len(test_iob_tagged_df_cleaned_reduced.sentence_num.unique()), \\\n",
    "test_iob_tagged_df_cleaned_reduced.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({'O': 21261,\n",
       "         'B-LOC': 1149,\n",
       "         'B-PER': 1001,\n",
       "         'I-PER': 688,\n",
       "         'I-LOC': 170,\n",
       "         'B-MISC': 396,\n",
       "         'I-MISC': 137,\n",
       "         'B-ORG': 1184,\n",
       "         'I-ORG': 470})"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_tag_counts = collections.Counter(test_iob_tagged_df_cleaned_reduced[\"tag\"])\n",
    "test_tag_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_getter = SentenceGetter(test_iob_tagged_df_cleaned_reduced)\n",
    "test_sentences = test_getter.sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "25"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test = [[vocab_to_int[w[0]] if w[0] in vocab_to_int.keys() else vocab_to_int['<UNK>'] for w in s]\\\n",
    "                                                            for s in test_sentences]\n",
    "X_test = pad_sequences(maxlen = max_len, sequences = X_test, padding  = 'post', value = vocab_to_int['<PAD>'])\n",
    "len(X_test[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test = [[tag2idx[w[3]] for w in s] for s in test_sentences]\n",
    "y_test = pad_sequences(maxlen = max_len, sequences = y_test, padding  = 'post', value = tag2idx['O'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test = [to_categorical(i, num_classes = n_tags) for i in y_test]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2884/2884 [==============================] - 9s 3ms/step\n"
     ]
    }
   ],
   "source": [
    "test_pred = model.predict(X_test, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_pred_labels = pred2label(test_pred)\n",
    "test_labels = pred2label(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1-score: 75.8%\n",
      "           precision    recall  f1-score   support\n",
      "\n",
      "      ORG       0.73      0.79      0.76      1184\n",
      "      PER       0.77      0.71      0.74      1001\n",
      "      LOC       0.88      0.82      0.85      1149\n",
      "     MISC       0.53      0.64      0.58       396\n",
      "\n",
      "micro avg       0.75      0.76      0.76      3730\n",
      "macro avg       0.76      0.76      0.76      3730\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"F1-score: {:.1%}\".format(f1_score(test_labels, test_pred_labels)))\n",
    "print(classification_report(test_labels, test_pred_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
